#!/usr/bin/env python3

"""
Clone a dhis2 installation from another server.
"""
import errno
import subprocess
import sys
import os
import time
import json
import argparse
from subprocess import Popen

import psycopg2

import process


TIME = time.strftime('%Y-%m-%d_%H%M')
COLOR = True


def main():
    global COLOR

    args = get_args()
    if args.no_color or not os.isatty(sys.stdout.fileno()):
        COLOR = False

    cfg = get_config(args.config, args.update_config)
    if args.check_only:
        sys.exit()
    elif args.update_config:
        update_config(args.config)
        sys.exit()

    dir_local, dir_remote = cfg['server_dir_local'], cfg['server_dir_remote']
    db_local, db_remote = cfg['db_local'], cfg['db_remote']

    if not args.manual_restart:
        stop_tomcat(dir_local)

    if not args.no_backups:
        backup_db(cfg['backups_dir'], cfg['backup_name'], db_local)
        backup_war(cfg['backups_dir'], dir_local, cfg['war_local'])

    if not args.no_webapps:
        route_remote = '%s:%s' % (cfg['hostname_remote'], dir_remote)
        get_webapps(dir_local, cfg['war_local'],
                    route_remote, cfg['war_remote'])

    if not args.no_db:
        get_db(db_local, db_remote, cfg['hostname_remote'])

    if args.post_sql:
        run_sql(db_local, args.post_sql)

    if args.post_clone_scripts:
        execute_scripts(cfg['post_clone_scripts_dir'])

    if not args.manual_restart:
        start_tomcat(dir_local)
        import_dir = cfg['post_process_import_dir'] if 'post_process_import_dir' in cfg else None
        if args.no_postprocess:
            log('No postprocessing done, as requested.')
        elif 'api_local' in cfg and 'postprocess' in cfg:
            process.postprocess(cfg['api_local'], cfg['postprocess']
                                , import_dir)
        else:
            log('No postprocessing done.')

        if args.post_clone_scripts:
            execute_scripts(cfg['post_clone_scripts_dir'], is_post_tomcat=True)

    else:
        log('Server not started automatically, as requested.')
        log('No postprocessing done.')


def get_args():
    "Return arguments"
    parser = argparse.ArgumentParser(description=__doc__)
    add = parser.add_argument  # shortcut
    add('config', help='file with configuration')
    add('--check-only', action='store_true', help='check config and exit')
    add('--no-backups', action='store_true', help="don't make backups")
    add('--no-webapps', action='store_true', help="don't clone the webapps")
    add('--no-db', action='store_true', help="don't clone the database")
    add('--no-postprocess', action='store_true', help="don't do postprocessing")
    add('--manual-restart', action='store_true', help="don't stop/start tomcat")
    add('--post-sql', nargs='+', default=[], help='sql files to run post-clone')
    add('--post-clone-scripts', action='store_true',
        help='execute all py and sh scripts in post_clone_scripts_dir')
    add('--post-import', action='store_true',
        help='import to DHIS2 selected json files from post_process_import_dir')
    add('--update-config', action='store_true', help='update the config file')
    add('--no-color', action='store_true', help="don't use colored output")
    return parser.parse_args()


def get_config(fname, update):
    "Return dict with the options read from configuration file"
    log('Reading from config file %s ...' % fname)
    try:
        with open(fname) as f:
            config = json.load(f)
        if get_version(config) != 2:
            if update:
                update_config(fname)
                sys.exit()
            else:
                raise ValueError('Old version of configuration file. Run with '
                                 '--update-config to upgrade.')
        check_config(config)
    except (AssertionError, IOError, ValueError) as e:
        sys.exit('Error reading config file %s: %s' % (fname, e))
    return config


def check_config(cfg):
    "Assert all the mandatory options in configuration exist and have reasonable values"
    for option in ['backups_dir', 'backup_name', 'hostname_remote',
                   'server_dir_local', 'server_dir_remote',
                   'db_local', 'db_remote', 'war_local', 'war_remote']:
        assert option in cfg, 'Missing option "%s"' % option

    if 'api_local' not in cfg:
        log('Option api_local missing. Will not do any postprocessing.')
    elif 'postprocess' not in cfg:
        log('Option postprocess missing. Will not do local postprocessing.')

    for path in ['backups_dir', 'server_dir_local', 'post_clone_scripts_dir',
                 'post_process_import_dir']:
        if path in cfg:
            assert os.path.isdir(cfg[path]), \
                '%s is not a directory: %s' % (path, cfg[path])
    assert (os.path.isfile(cfg['server_dir_local'] + '/bin/startup.sh') and
            os.path.isfile(cfg['server_dir_local'] + '/bin/shutdown.sh')), \
            ('%s should be a directory with start/stop scripts in bin: %s' %
             ('server_dir_local', cfg['server_dir_local']))
    for uri in ['db_local', 'db_remote']:
        assert is_good_db_uri(cfg[uri]), 'bad %s uri: %s' % (uri, cfg[uri])
    for war in ['war_local', 'war_remote']:
        assert cfg[war].endswith('.war'), \
            'war file does not end with .war: %s' % cfg[war]
    log('Configuration looks OK.')


def update_config(fname):
    "Update the configuration file from an old format to the current one"
    with open(fname) as f:
        config = json.load(f)

    if get_version(config) == 2:
        log('The current configuration file is valid. Nothing to update.')
    else:
        if 'postprocess' in config:
            entries = []
            for entry in config['postprocess']:
                entries += update_entry(entry)
            config['postprocess'] = entries
        name, ext = os.path.splitext(fname)
        fname_new = name + '_updated' + ext
        log('Writing updated configuration in %s' % fname_new)
        with open(fname_new, 'wt') as fnew:
            json.dump(config, fnew, indent=2)


def update_entry(entry_old):
    "Return a list of dictionaries that correspond to the actions in entry"
    entries = []

    # Get the selected users part.
    users = {}
    if 'usernames' in entry_old:
        users['selectUsernames'] = entry_old['usernames']
    if 'fromGroups' in entry_old:
        users['selectFromGroups'] = entry_old['fromGroups']

    # Add a new entry for each action described in the old entry.
    old_actions = ['addRoles', 'addRolesFromTemplate']
    if all(action not in entry_old for action in old_actions):
        entry_new = users.copy()
        entry_new['action'] = 'activate'
        entries.append(entry_new)
    else:
        for action in old_actions:
            if action in entry_old:
                entry_new = users.copy()
                entry_new['action'] = action
                entry_new[action] = entry_old[action]
                entries.append(entry_new)

    return entries



def get_version(config):
    "Return the highest version for which the given configuration is valid"
    if 'postprocess' not in config or not config['postprocess']:
        return 2
    for entry in config['postprocess']:
        if 'usernames' in entry or 'fromGroups' in entry:
            return 1
        if 'selectUsernames' in entry or 'selectFromGroups' in entry:
            return 2
    raise ValueError('Unknown version of configuration file.')


def is_good_db_uri(uri):
    return uri.startswith('postgresql://')  # we could be way more sophisticated


def run(cmd):
    log(cmd)
    ret = os.system(cmd)
    if ret != 0:
        sys.exit(ret)


def log(txt):
    out = '[%s] %s' % (time.strftime('%Y-%m-%d %T'), txt)
    print((magenta(out) if COLOR else out))
    sys.stdout.flush()


def magenta(txt):
    return '\x1b[35m%s\x1b[0m' % txt


def execute_scripts(dirname, is_post_tomcat=False):
    is_script = lambda fname: os.path.splitext(fname)[-1] in ['.sh', '.py']
    is_normal = lambda fname: not fname.startswith("post")
    is_post = lambda fname: fname.startswith("post")
    applied_filter = is_post if is_post_tomcat else is_normal
    files_list = filter(applied_filter, os.listdir(dirname))

    for script in sorted(filter(is_script, files_list)):
        run('"%s/%s"' % (dirname, script))


def start_tomcat(server_path):
    run('"%s/bin/startup.sh"' % server_path)


def stop_tomcat(server_path):
    run('"%s/bin/shutdown.sh"' % server_path)


def backup_db(backups_dir, backup_name, db_local):
    backup_file = '%s/%s_%s.dump' % (backups_dir, backup_name, TIME)
    run("pg_dump --file '%s' --format custom --exclude-schema sys --clean '%s' "
        % (backup_file, db_local))


def backup_war(backups_dir, dir_local, war_local):
    backup_file = '%s/%s_%s.war' % (backups_dir, war_local[:-4], TIME)
    run('cp "%s/webapps/%s" "%s"' % (dir_local, war_local, backup_file))


def get_webapps(route_local, war_local, route_remote, war_remote):
    for mandatory, subdir in [[True, 'webapps'], [False, 'files']]:
        cmd = ("rsync -a --delete %s/%s/* %s/%s" % (route_remote, subdir, route_local, subdir))
        p = Popen(cmd, shell=True, stdout=subprocess.PIPE, stdin=subprocess.PIPE,
                  universal_newlines=True, stderr=subprocess.PIPE)
        stdout, stderr = p.communicate()
        if p.returncode != 0 and mandatory:
            log('Mandatory folder %s failed to rsync' % subdir)
            raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT) + '\n' + stderr, subdir)

    if war_local != war_remote:
        commands = [
            'cd "%s/webapps"' % route_local,
            'rm -f "%s"' % war_local,  # the war file itself
            'mv "%s" "%s"' % (war_remote, war_local),
            'rm -rf "%s"' % war_local[:-4],  # the directory
            'mv "%s" "%s"' % (war_remote[:-4], war_local[:-4])]
        run('; '.join(commands))


def get_db(db_local, db_remote, hostname_remote):
    "Replace the contents of db_local with db_remote"
    empty_db(db_local)
    exclude = ("--exclude-table 'aggregated*' --exclude-table 'analytics*' "
               "--exclude-table 'completeness*' --exclude-schema sys")
    dump = "pg_dump -d '%s' --no-owner %s" % (db_remote, exclude)
    cmd = "ssh %s %s | psql -d '%s'" % (hostname_remote, dump, db_local)
    run(cmd + " 2>&1 | paste - - - | uniq -c")  # run with more compact output
    # Errors like 'ERROR: role "u_dhis2" does not exist' are expected
    # and safe to ignore.

    # We could skip the "ssh hostname_remote" part if we can access the
    # remote DB from the local machine, but we keep it in case we can't.

    # I'd prefer to do it with postgres custom format and pg_restore:
    #    dump = ("pg_dump -d '%s' --format custom --clean --no-owner %s" %
    #            (db_remote, exclude))
    #    user = db_local[len('postgresql://'):].split(':')[0]
    #    run("ssh %s %s | pg_restore -d '%s' --no-owner --role %s" %
    #        (hostname_remote, dump, db_local, user))
    # but it causes problems with the user role.


def empty_db(db_local):
    "Empty the contents of database"
    db_name = db_local.split('/')[-1]
    postgis_elements = {'geography_columns', 'geometry_columns',
                        'raster_columns', 'raster_overviews',
                        'spatial_ref_sys', 'pg_stat_statements'}

    with psycopg2.connect(db_local) as conn:
        with conn.cursor() as cur:
            def fetch(name):
                prefix = {'views': 'table',
                          'tables': 'table',
                          'sequences': 'sequence'}[name]
                cur.execute(
                    "SELECT %(prefix)s_name FROM information_schema.%(name)s "
                    "WHERE %(prefix)s_schema='public' "
                    "AND %(prefix)s_catalog='%(db_name)s'" %
                    {'prefix': prefix, 'name': name, 'db_name': db_name})
                results_tuples = cur.fetchall()
                results = set(list(zip(*results_tuples))[0] if results_tuples else [])

                return results - postgis_elements

            def drop(name):
                xs = fetch(name)
                log("Dropping %d %s..." % (len(xs), name))
                kind = name[:-1].upper()  # "tables" -> "TABLE"
                for x in xs:
                    cur.execute("DROP %s IF EXISTS %s CASCADE" % (kind, x))
                    conn.commit()

            drop('views')
            drop('tables')
            drop('sequences')

            # If we had permissions, it would be as simple as a
            #   DROP DATABASE dbname
            #   CREATE DATABASE dbname
            # but we may not have those permissions.


def run_sql(db_local, post_sql):
    for fname in post_sql:
        run("psql -d '%s' < '%s'" % (db_local, fname))



if __name__ == '__main__':
    main()
